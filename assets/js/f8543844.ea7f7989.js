"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[1197],{8424:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>c,toc:()=>d});var t=n(5893),r=n(1151);const s={sidebar_position:2},o="Configuration",c={id:"guides/adaptative-concurreny-limiter/configuration",title:"Configuration",description:"In this section, we will introduce how configuration is done in LoadShedding.",source:"@site/docs/guides/adaptative-concurreny-limiter/configuration.md",sourceDirName:"guides/adaptative-concurreny-limiter",slug:"/guides/adaptative-concurreny-limiter/configuration",permalink:"/loadshedding/docs/guides/adaptative-concurreny-limiter/configuration",draft:!1,unlisted:!1,editUrl:"https://github.com/farfetch/loadhsedding/tree/main/website/docs/guides/adaptative-concurreny-limiter/configuration.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Adaptative Concurrency Limiter",permalink:"/loadshedding/docs/guides/adaptative-concurreny-limiter/adaptative_concurrency_limiter"},next:{title:"Reference",permalink:"/loadshedding/docs/category/reference"}},l={},d=[{value:"Options Configuration",id:"options-configuration",level:2},{value:"Events Listener Configuration",id:"events-listener-configuration",level:2},{value:"Custom Queue Size Calculator Configuration",id:"custom-queue-size-calculator-configuration",level:2},{value:"1 - Implement the IQueueSizeCalculator interface",id:"1---implement-the-iqueuesizecalculator-interface",level:3},{value:"2 - Use a custom QueueSizeCalculator",id:"2---use-a-custom-queuesizecalculator",level:3},{value:"Request Prioritization Configuration",id:"request-prioritization-configuration",level:2},{value:"Http Header Priority Resolver",id:"http-header-priority-resolver",level:3},{value:"Endpoint Priority Resolver",id:"endpoint-priority-resolver",level:3},{value:"Metrics",id:"metrics",level:2},{value:"Install Package",id:"install-package",level:3},{value:"Configure",id:"configure",level:3},{value:"Reference Documentation",id:"reference-documentation",level:3}];function a(e){const i={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.h1,{id:"configuration",children:"Configuration"}),"\n",(0,t.jsx)(i.p,{children:"In this section, we will introduce how configuration is done in LoadShedding."}),"\n",(0,t.jsx)(i.p,{children:"LoadShedding is a highly configured framework. You can customize it through a Fluent Builder."}),"\n",(0,t.jsx)(i.p,{children:"There are a few options to configure LoadShedding:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.a,{href:"#configuration",children:"Configuration"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.a,{href:"#options-configuration",children:"Options Configuration"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.a,{href:"#events-listener-configuration",children:"Events Listener Configuration"})}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.a,{href:"#custom-queue-size-calculator-configuration",children:"Custom Queue Size Calculator Configuration"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.a,{href:"#1---implement-the-iqueuesizecalculator-interface",children:"1 - Implement the IQueueSizeCalculator interface"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.a,{href:"#2---use-a-custom-queuesizecalculator",children:"2 - Use a custom QueueSizeCalculator"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.a,{href:"#request-prioritization-configuration",children:"Request Prioritization Configuration"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.a,{href:"#http-header-priority-resolver",children:"Http Header Priority Resolver"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.a,{href:"#endpoint-priority-resolver",children:"Endpoint Priority Resolver"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.a,{href:"#metrics",children:"Metrics"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.a,{href:"#install-package",children:"Install Package"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.a,{href:"#configure",children:"Configure"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.a,{href:"#reference-documentation",children:"Reference Documentation"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"options-configuration",children:"Options Configuration"}),"\n",(0,t.jsx)(i.p,{children:"It is possible to have access to additional configurations when registering the services."}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-csharp",children:'services.AddLoadShedding((provider, options) =>\n{\n    options.AdaptativeLimiter.ConcurrencyOptions.MinQueueSize = 10;\n    options.AdaptativeLimiter.UseHeaderPriorityResolver();\n    options.SubscribeEvents(events =>\n    {\n        events.ItemEnqueued.Subscribe(args => Console.WriteLine($"QueueLimit: {args.QueueLimit}, QueueCount: {args.QueueCount}"));\n        events.ItemDequeued.Subscribe(args => Console.WriteLine($"QueueLimit: {args.QueueLimit}, QueueCount: {args.QueueCount}"));\n        events.ItemProcessing.Subscribe(args => Console.WriteLine($"ConcurrencyLimit: {args.ConcurrencyLimit}, ConcurrencyItems: {args.ConcurrencyCount}"));\n        events.ItemProcessed.Subscribe(args => Console.WriteLine($"ConcurrencyLimit: {args.ConcurrencyLimit}, ConcurrencyItems: {args.ConcurrencyCount}"));\n        events.Rejected.Subscribe(args => Console.Error.WriteLine($"Item rejected with Priority: {args.Priority}"));\n    });\n});\n'})}),"\n",(0,t.jsxs)(i.p,{children:["By default, the following ",(0,t.jsx)(i.code,{children:"ConcurrencyOptions"})," values will be used:"]}),"\n",(0,t.jsxs)(i.table,{children:[(0,t.jsx)(i.thead,{children:(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.th,{children:"Option"}),(0,t.jsx)(i.th,{children:"Description"}),(0,t.jsx)(i.th,{children:"Default Value"})]})}),(0,t.jsxs)(i.tbody,{children:[(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"MinConcurrencyLimit"}),(0,t.jsx)(i.td,{children:"The minimum number of concurrent requests allowed"}),(0,t.jsx)(i.td,{children:"5"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"InitialConcurrencyLimit"}),(0,t.jsx)(i.td,{children:"The starting number of concurrent requests allowed. This may be adjusted up or down based on the performance of the system"}),(0,t.jsx)(i.td,{children:"5"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"MaxConcurrencyLimit"}),(0,t.jsx)(i.td,{children:"The maximum number of concurrent requests allowed"}),(0,t.jsx)(i.td,{children:"500"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"Tolerance"}),(0,t.jsx)(i.td,{children:"The level of flexibility in adjusting the concurrency limit. It indicates how much change in the minimum latency is acceptable before lowering the concurrency limit threshold. A high tolerance means the system can adjust the concurrency limit more freely, while a low tolerance means the limit will be maintained more strictly. For example, a value of 2.0 means a 2x increase in latency is acceptable"}),(0,t.jsx)(i.td,{children:"1.5"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"MinQueueSize"}),(0,t.jsx)(i.td,{children:"The minimum number of requests that must be waiting in the queue before new requests can be processed"}),(0,t.jsx)(i.td,{children:"20"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"InitialQueueSize"}),(0,t.jsx)(i.td,{children:"The starting number of requests in the queue"}),(0,t.jsx)(i.td,{children:"20"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"QueueTimeoutInMs"}),(0,t.jsx)(i.td,{children:"The queue waiting timeout, when the timeout is reached the task will be canceled and will throw an OperationCanceledException."}),(0,t.jsx)(i.td,{children:"Infinite"})]})]})]}),"\n",(0,t.jsxs)(i.admonition,{type:"note",children:[(0,t.jsx)(i.mdxAdmonitionTitle,{}),(0,t.jsx)(i.p,{children:"These default values were defined based on:"}),(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["Investigation of the ",(0,t.jsx)(i.a,{href:"https://github.com/Netflix/concurrency-limits",children:"Netflix Concurrency Limit"})," tool."]}),"\n",(0,t.jsx)(i.li,{children:"Having a huge margin of tolerance: accepting 500 requests simultaneously (and 50 more going to the queue - initially)."}),"\n"]})]}),"\n",(0,t.jsxs)(i.p,{children:["On the other hand, if needed, these settings can be completely overridden by using the ",(0,t.jsx)(i.code,{children:"ConcurrencyOptions"})," property:"]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-csharp",children:"services.AddLoadShedding((provider, options) =>\n{\n    options.AdaptativeLimiter.ConcurrencyOptions.MinConcurrencyLimit = 5;\n    options.AdaptativeLimiter.ConcurrencyOptions.InitialConcurrencyLimit = 5;\n    options.AdaptativeLimiter.ConcurrencyOptions.InitialQueueSize = 50;\n    options.AdaptativeLimiter.ConcurrencyOptions.Tolerance = 2;\n    options.AdaptativeLimiter.ConcurrencyOptions.QueueTimeoutInMs = 60000;\n});\n"})}),"\n",(0,t.jsx)(i.p,{children:"When defining the options values, the following criteria need to be accomplished:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"MinConcurrencyLimit, InitialConcurrencyLimit, MaxConcurrencyLimit, MinQueueSize, and MinQueueSize >= 1"}),"\n",(0,t.jsx)(i.li,{children:"Tolerance > 1"}),"\n",(0,t.jsx)(i.li,{children:"MaxConcurrencyLimit > MinConcurrencyLimit"}),"\n",(0,t.jsx)(i.li,{children:"InitialConcurrencyLimit >= MinConcurrencyLimit && MaxConcurrencyLimit >= InitialConcurrencyLimit"}),"\n",(0,t.jsx)(i.li,{children:"InitialQueueSize >= MinQueueSize"}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"events-listener-configuration",children:"Events Listener Configuration"}),"\n",(0,t.jsx)(i.p,{children:"It is possible to monitor the service performance by subscribing internal events:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"QueueLimitChanged: invoked whenever the queue limit is changed."}),"\n",(0,t.jsx)(i.li,{children:"QueueItemsCountChanged: invoked whenever an item is enqueued or dequeued."}),"\n",(0,t.jsx)(i.li,{children:"ConcurrencyLimitChanged: invoked whenever the concurrency limit is changed."}),"\n",(0,t.jsx)(i.li,{children:"ConcurrentItemsCountChanged: invoked whenever an item is being processed or it is finished."}),"\n",(0,t.jsx)(i.li,{children:"ItemEnqueued: invoked whenever a task is enqueued."}),"\n",(0,t.jsx)(i.li,{children:"ItemDequeued: invoked whenever a task is dequeued."}),"\n",(0,t.jsx)(i.li,{children:"Rejected: invoked whenever there are rejected requests - queue limit is reached."}),"\n"]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-csharp",children:'services.AddLoadShedding((provider, options) =>\n{\n    options.SubscribeEvents(events =>\n    {\n        events.ItemEnqueued.Subscribe(args => Console.WriteLine($"QueueLimit: {args.QueueLimit}, QueueCount: {args.QueueCount}"));\n        events.ItemDequeued.Subscribe(args => Console.WriteLine($"QueueLimit: {args.QueueLimit}, QueueCount: {args.QueueCount}"));\n        events.ItemProcessing.Subscribe(args => Console.WriteLine($"ConcurrencyLimit: {args.ConcurrencyLimit}, ConcurrencyItems: {args.ConcurrencyCount}"));\n        events.ItemProcessed.Subscribe(args => Console.WriteLine($"ConcurrencyLimit: {args.ConcurrencyLimit}, ConcurrencyItems: {args.ConcurrencyCount}"));\n        events.Rejected.Subscribe(args => Console.Error.WriteLine($"Item rejected with Priority: {args.Priority}"));\n    });\n});\n'})}),"\n",(0,t.jsx)(i.h2,{id:"custom-queue-size-calculator-configuration",children:"Custom Queue Size Calculator Configuration"}),"\n",(0,t.jsx)(i.p,{children:"Calculating the queue size has the main goal to find the maximum value of requests allowed to be in the queue."}),"\n",(0,t.jsx)(i.p,{children:"The default queue size calculator is based on the square root of the concurrency limit value."}),"\n",(0,t.jsx)(i.p,{children:"Optionally, the strategy can be overridden by:"}),"\n",(0,t.jsx)(i.h3,{id:"1---implement-the-iqueuesizecalculator-interface",children:"1 - Implement the IQueueSizeCalculator interface"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-csharp",children:"    public class CustomQueueSizeCalculator : IQueueSizeCalculator\n    {\n        public int CalculateQueueSize(IConcurrencyContext context)\n        {\n            // Implement the Calculate Queue Size logic here\n\n            return default;\n        }\n    }\n"})}),"\n",(0,t.jsx)(i.h3,{id:"2---use-a-custom-queuesizecalculator",children:"2 - Use a custom QueueSizeCalculator"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-csharp",children:"services.AddLoadShedding((provider, options) =>\n{\n    options.AdaptativeLimiter.QueueSizeCalculator = new CustomQueueSizeCalculator();\n});\n"})}),"\n",(0,t.jsx)(i.h2,{id:"request-prioritization-configuration",children:"Request Prioritization Configuration"}),"\n",(0,t.jsx)(i.p,{children:"It is possible to configure the settings to establish priority resolvers for requests."}),"\n",(0,t.jsx)(i.p,{children:"At present, only one strategy is supported, which means that solely the most recently configured strategy will be implemented."}),"\n",(0,t.jsx)(i.h3,{id:"http-header-priority-resolver",children:"Http Header Priority Resolver"}),"\n",(0,t.jsxs)(i.p,{children:["With the extension ",(0,t.jsx)(i.code,{children:"UseHeaderPriorityResolver"})," it will automatically convert the value of the HTTP Header ",(0,t.jsx)(i.code,{children:"X-Priority"})," to the request priority."]}),"\n",(0,t.jsx)(i.p,{children:"The allowed values are: critical, normal and non-critical"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-csharp",children:"services.AddLoadShedding((provider, options) =>\n{\n    options.AdaptativeLimiter.UseHeaderPriorityResolver();\n});\n"})}),"\n",(0,t.jsx)(i.h3,{id:"endpoint-priority-resolver",children:"Endpoint Priority Resolver"}),"\n",(0,t.jsxs)(i.p,{children:["With the extension ",(0,t.jsx)(i.code,{children:"UseEndpointPriorityResolver"})," it will automatically load the Priority defined for the endpoint from the ",(0,t.jsx)(i.code,{children:"EndpointPriorityAttribute"}),"."]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-csharp",children:"services.AddLoadShedding((provider, options) =>\n{\n    options.AdaptativeLimiter.UseEndpointPriorityResolver();\n});\n"})}),"\n",(0,t.jsxs)(i.p,{children:["Also, add ",(0,t.jsx)(i.code,{children:"EndpointPriorityAttribute"})," in the action."]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-csharp",children:'[HttpGet]\n[Route("people")]\n[EndpointPriority(Priority.Critical)]\npublic async Task<IActionResult> GetPeopleAsync()\n{\n    return this.Ok(new[]\n    {\n        new Person\n        {\n            Id = 1,\n            Age = 18,\n            UserName = "john.doe"\n        }\n    });\n}\n'})}),"\n",(0,t.jsx)(i.h2,{id:"metrics",children:"Metrics"}),"\n",(0,t.jsx)(i.p,{children:"The library has the option to export adaptative limiter metrics to Prometheus."}),"\n",(0,t.jsx)(i.h3,{id:"install-package",children:"Install Package"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-bash",children:"dotnet add package Farfetch.LoadShedding.Prometheus\n"})}),"\n",(0,t.jsx)(i.h3,{id:"configure",children:"Configure"}),"\n",(0,t.jsxs)(i.p,{children:["Use the ",(0,t.jsx)(i.code,{children:"LoadSheddingOptions"})," extension method ",(0,t.jsx)(i.code,{children:"AddMetrics()"}),".\nThe metrics includes the label ",(0,t.jsx)(i.code,{children:"method"})," that describes the HTTP method. For this value to be correctly parsed, the ",(0,t.jsx)(i.code,{children:"HTTPContextAccessor"})," should be included otherwise the ",(0,t.jsx)(i.code,{children:"method"})," label will output the value ",(0,t.jsx)(i.code,{children:"UNKNOWN"}),"."]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-csharp",children:"builder.Services.AddHttpContextAccessor();\n\nservices.AddLoadShedding((provider, options) =>\n{\n    options.AddMetrics();\n});\n"})}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.code,{children:"AddMetrics"})," has additional options that supports renaming and enable/disable specific metrics."]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-csharp",children:"options.AddMetrics(options =>\n{\n    options.QueueLimit.Enabled = false;\n    options.ConcurrencyLimit.Enabled = false;\n    options.RequestRejected.Enabled = false;\n});\n"})}),"\n",(0,t.jsx)(i.h3,{id:"reference-documentation",children:"Reference Documentation"}),"\n",(0,t.jsxs)(i.table,{children:[(0,t.jsx)(i.thead,{children:(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.th,{children:"Metric Name"}),(0,t.jsx)(i.th,{children:"Metric Description"}),(0,t.jsx)(i.th,{children:"Metric Type"}),(0,t.jsx)(i.th,{children:"Labels"})]})}),(0,t.jsxs)(i.tbody,{children:[(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"http_requests_concurrency_items_total"}),(0,t.jsx)(i.td,{children:"The current number of executions concurrently"}),(0,t.jsx)(i.td,{children:"gauge"}),(0,t.jsx)(i.td,{})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"http_requests_concurrency_limit_total"}),(0,t.jsx)(i.td,{children:"The current concurrency limit"}),(0,t.jsx)(i.td,{children:"gauge"}),(0,t.jsx)(i.td,{})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"http_requests_queue_items_total"}),(0,t.jsx)(i.td,{children:"The current number of items waiting to be processed in the queue"}),(0,t.jsx)(i.td,{children:"gauge"}),(0,t.jsx)(i.td,{children:"method (HTTP method of the request), priority (critical, noncritical, normal)"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"http_requests_queue_limit_total"}),(0,t.jsx)(i.td,{children:"The current queue limit size"}),(0,t.jsx)(i.td,{children:"gauge"}),(0,t.jsx)(i.td,{})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"http_requests_queue_time_seconds"}),(0,t.jsx)(i.td,{children:"The time each request spent in the queue until its executed"}),(0,t.jsx)(i.td,{children:"histogram"}),(0,t.jsx)(i.td,{children:"method (HTTP method of the request), priority (critical, noncritical, normal)"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:"http_requests_rejected_total"}),(0,t.jsx)(i.td,{children:"The number of requests rejected because the queue limit is reached"}),(0,t.jsx)(i.td,{children:"counter"}),(0,t.jsx)(i.td,{children:"method (HTTP method of the request), priority (critical, noncritical, normal), reason (max_queue_items, queue_timeout)"})]})]})]})]})}function u(e={}){const{wrapper:i}={...(0,r.a)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(a,{...e})}):a(e)}},1151:(e,i,n)=>{n.d(i,{Z:()=>c,a:()=>o});var t=n(7294);const r={},s=t.createContext(r);function o(e){const i=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function c(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(s.Provider,{value:i},e.children)}}}]);